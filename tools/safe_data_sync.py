#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®‰å…¨è³‡æ–™åŒæ­¥å·¥å…·
åŠŸèƒ½ï¼šè™•ç† created_at æ¬„ä½çš„è³‡æ–™åŒæ­¥å•é¡Œ
è§£æ±ºæ–¹æ¡ˆï¼š
1. ä½¿ç”¨è³‡æ–™åº«è‡ªå‹•è¨­å®šæ™‚é–“æˆ³
2. æä¾›å®‰å…¨çš„è³‡æ–™åŒ¯å…¥/åŒ¯å‡ºåŠŸèƒ½
3. é¿å…æ™‚é–“æ¬„ä½è¡çª
"""

import os
import sys
import datetime
from sqlalchemy import create_engine, text
from sqlalchemy.exc import SQLAlchemyError
import json

def get_database_connection():
    """å–å¾—è³‡æ–™åº«é€£ç·š"""
    DATABASE_URL = "mysql+aiomysql://gae252g1usr:gae252g1PSWD%21@35.201.153.17:3306/gae252g1_db"
    pymysql_url = DATABASE_URL.replace("mysql+aiomysql://", "mysql+pymysql://")
    return create_engine(pymysql_url)

def export_data_without_timestamps(table_name, output_file=None):
    """
    åŒ¯å‡ºè³‡æ–™æ™‚æ’é™¤æ™‚é–“æˆ³æ¬„ä½
    é¿å…åŒæ­¥æ™‚çš„æ™‚é–“è¡çªå•é¡Œ
    """
    engine = get_database_connection()
    
    try:
        with engine.connect() as connection:
            # ç²å–è¡¨æ ¼çµæ§‹
            desc_result = connection.execute(text(f"DESCRIBE {table_name}"))
            columns = desc_result.fetchall()
            
            # éæ¿¾æ‰æ™‚é–“æˆ³æ¬„ä½
            timestamp_columns = ['created_at', 'updated_at', 'order_time', 'upload_time']
            safe_columns = []
            
            for col in columns:
                field_name = col[0]
                if field_name not in timestamp_columns:
                    safe_columns.append(field_name)
            
            print(f"ğŸ“‹ å®‰å…¨æ¬„ä½åˆ—è¡¨: {safe_columns}")
            
            # åŒ¯å‡ºè³‡æ–™
            columns_str = ', '.join(safe_columns)
            query = f"SELECT {columns_str} FROM {table_name}"
            result = connection.execute(text(query))
            
            data = []
            for row in result.fetchall():
                row_dict = {}
                for i, col_name in enumerate(safe_columns):
                    value = row[i]
                    # è™•ç†ç‰¹æ®Šè³‡æ–™é¡å‹
                    if isinstance(value, datetime.datetime):
                        value = value.isoformat()
                    row_dict[col_name] = value
                data.append(row_dict)
            
            # å„²å­˜åˆ°æª”æ¡ˆ
            if output_file is None:
                output_file = f"{table_name}_export.json"
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… æˆåŠŸåŒ¯å‡º {len(data)} ç­†è³‡æ–™åˆ° {output_file}")
            print(f"âš ï¸  å·²æ’é™¤æ™‚é–“æˆ³æ¬„ä½: {timestamp_columns}")
            
            return output_file
            
    except SQLAlchemyError as e:
        print(f"âŒ åŒ¯å‡ºå¤±æ•—: {e}")
        return None

def import_data_safely(table_name, data_file):
    """
    å®‰å…¨åŒ¯å…¥è³‡æ–™ï¼Œè®“è³‡æ–™åº«è‡ªå‹•è¨­å®šæ™‚é–“æˆ³
    """
    engine = get_database_connection()
    
    try:
        # è®€å–è³‡æ–™
        with open(data_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if not data:
            print("âŒ æ²’æœ‰è³‡æ–™å¯åŒ¯å…¥")
            return False
        
        with engine.connect() as connection:
            # ç²å–è¡¨æ ¼çµæ§‹
            desc_result = connection.execute(text(f"DESCRIBE {table_name}"))
            columns = desc_result.fetchall()
            
            # æ‰¾å‡ºæ™‚é–“æˆ³æ¬„ä½
            timestamp_columns = ['created_at', 'updated_at', 'order_time', 'upload_time']
            auto_timestamp_columns = []
            
            for col in columns:
                field_name = col[0]
                field_type = col[1]
                if field_name in timestamp_columns and 'CURRENT_TIMESTAMP' in str(col[5]):
                    auto_timestamp_columns.append(field_name)
            
            print(f"ğŸ• è‡ªå‹•æ™‚é–“æˆ³æ¬„ä½: {auto_timestamp_columns}")
            
            # æº–å‚™åŒ¯å…¥è³‡æ–™
            success_count = 0
            for item in data:
                try:
                    # ç§»é™¤æ™‚é–“æˆ³æ¬„ä½ï¼Œè®“è³‡æ–™åº«è‡ªå‹•è¨­å®š
                    safe_item = {}
                    for key, value in item.items():
                        if key not in timestamp_columns:
                            safe_item[key] = value
                    
                    # å»ºç«‹ INSERT èªå¥
                    columns = list(safe_item.keys())
                    values = list(safe_item.values())
                    placeholders = ', '.join(['%s'] * len(columns))
                    columns_str = ', '.join(columns)
                    
                    insert_sql = f"INSERT INTO {table_name} ({columns_str}) VALUES ({placeholders})"
                    
                    connection.execute(text(insert_sql), values)
                    success_count += 1
                    
                except Exception as e:
                    print(f"âŒ åŒ¯å…¥é …ç›®å¤±æ•—: {e}")
                    print(f"   é …ç›®è³‡æ–™: {item}")
            
            connection.commit()
            print(f"âœ… æˆåŠŸåŒ¯å…¥ {success_count} ç­†è³‡æ–™")
            print(f"âš ï¸  æ™‚é–“æˆ³ç”±è³‡æ–™åº«è‡ªå‹•è¨­å®š")
            
            return True
            
    except Exception as e:
        print(f"âŒ åŒ¯å…¥å¤±æ•—: {e}")
        return False

def create_safe_sync_script(table_name):
    """
    å»ºç«‹å®‰å…¨çš„åŒæ­¥è…³æœ¬
    """
    script_content = f"""#!/usr/bin/env python3
# -*- coding: utf-8 -*-
\"\"\"
å®‰å…¨åŒæ­¥è…³æœ¬ - {table_name}
åŠŸèƒ½ï¼šå®‰å…¨åœ°åŒæ­¥ {table_name} è¡¨æ ¼çš„è³‡æ–™
\"\"\"

import os
import sys
import json
from sqlalchemy import create_engine, text
from sqlalchemy.exc import SQLAlchemyError

def sync_{table_name}_data():
    \"\"\"
    åŒæ­¥ {table_name} è³‡æ–™
    \"\"\"
    # è³‡æ–™åº«é€£ç·šè¨­å®š
    DATABASE_URL = "mysql+pymysql://gae252g1usr:gae252g1PSWD%21@35.201.153.17:3306/gae252g1_db"
    engine = create_engine(DATABASE_URL)
    
    try:
        with engine.connect() as connection:
            # 1. åŒ¯å‡ºç¾æœ‰è³‡æ–™ï¼ˆæ’é™¤æ™‚é–“æˆ³ï¼‰
            print("ğŸ“¤ åŒ¯å‡ºç¾æœ‰è³‡æ–™...")
            export_query = f\"\"\"
            SELECT * FROM {table_name}
            \"\"\"
            result = connection.execute(text(export_query))
            
            # éæ¿¾æ™‚é–“æˆ³æ¬„ä½
            timestamp_columns = ['created_at', 'updated_at', 'order_time', 'upload_time']
            data = []
            
            for row in result.fetchall():
                row_dict = {{}}
                for i, col in enumerate(result.keys()):
                    if col not in timestamp_columns:
                        row_dict[col] = row[i]
                data.append(row_dict)
            
            # 2. å„²å­˜å‚™ä»½
            backup_file = f"{table_name}_backup.json"
            with open(backup_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… å‚™ä»½å·²å„²å­˜åˆ° {{backup_file}}")
            print(f"âš ï¸  å·²æ’é™¤æ™‚é–“æˆ³æ¬„ä½: {{timestamp_columns}}")
            
            return True
            
    except Exception as e:
        print(f"âŒ åŒæ­¥å¤±æ•—: {{e}}")
        return False

if __name__ == "__main__":
    sync_{table_name}_data()
"""
    
    script_file = f"sync_{table_name}.py"
    with open(script_file, 'w', encoding='utf-8') as f:
        f.write(script_content)
    
    print(f"âœ… åŒæ­¥è…³æœ¬å·²å»ºç«‹: {script_file}")
    return script_file

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ å®‰å…¨è³‡æ–™åŒæ­¥å·¥å…·")
    print("=" * 50)
    
    while True:
        print("\nğŸ“‹ è«‹é¸æ“‡æ“ä½œï¼š")
        print("1. åŒ¯å‡ºè³‡æ–™ï¼ˆæ’é™¤æ™‚é–“æˆ³ï¼‰")
        print("2. åŒ¯å…¥è³‡æ–™ï¼ˆå®‰å…¨æ¨¡å¼ï¼‰")
        print("3. å»ºç«‹åŒæ­¥è…³æœ¬")
        print("4. æª¢æŸ¥è¡¨æ ¼çµæ§‹")
        print("5. é€€å‡º")
        
        choice = input("\nè«‹è¼¸å…¥é¸é … (1-5): ").strip()
        
        if choice == '1':
            table_name = input("è«‹è¼¸å…¥è¡¨æ ¼åç¨±: ").strip()
            output_file = input("è«‹è¼¸å…¥è¼¸å‡ºæª”æ¡ˆåç¨± (ç•™ç©ºä½¿ç”¨é è¨­): ").strip()
            if not output_file:
                output_file = None
            
            export_data_without_timestamps(table_name, output_file)
            
        elif choice == '2':
            table_name = input("è«‹è¼¸å…¥è¡¨æ ¼åç¨±: ").strip()
            data_file = input("è«‹è¼¸å…¥è³‡æ–™æª”æ¡ˆè·¯å¾‘: ").strip()
            
            import_data_safely(table_name, data_file)
            
        elif choice == '3':
            table_name = input("è«‹è¼¸å…¥è¡¨æ ¼åç¨±: ").strip()
            create_safe_sync_script(table_name)
            
        elif choice == '4':
            table_name = input("è«‹è¼¸å…¥è¡¨æ ¼åç¨±: ").strip()
            engine = get_database_connection()
            
            try:
                with engine.connect() as connection:
                    desc_result = connection.execute(text(f"DESCRIBE {table_name}"))
                    columns = desc_result.fetchall()
                    
                    print(f"\nğŸ“‹ {table_name} è¡¨æ ¼çµæ§‹:")
                    print("-" * 60)
                    for col in columns:
                        field, type_name, null, key, default, extra = col
                        print(f"{field:<20} {type_name:<20} {null:<8} {key:<8} {str(default):<15} {extra}")
                        
            except Exception as e:
                print(f"âŒ æª¢æŸ¥å¤±æ•—: {e}")
                
        elif choice == '5':
            print("ğŸ‘‹ å†è¦‹ï¼")
            break
            
        else:
            print("âŒ ç„¡æ•ˆé¸é …ï¼Œè«‹é‡æ–°é¸æ“‡")

if __name__ == "__main__":
    main()
