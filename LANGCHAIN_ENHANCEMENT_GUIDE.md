# LangChain å¼·åŒ–åŠŸèƒ½èªªæ˜æ›¸

## ğŸ“‹ ç›®éŒ„
1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [LangChain å¼·åŒ–åŠŸèƒ½](#langchain-å¼·åŒ–åŠŸèƒ½)
3. [å®‰è£å’Œè¨­å®š](#å®‰è£å’Œè¨­å®š)
4. [ä½¿ç”¨æ–¹å¼](#ä½¿ç”¨æ–¹å¼)
5. [åŠŸèƒ½æ¯”è¼ƒ](#åŠŸèƒ½æ¯”è¼ƒ)
6. [æœ€ä½³å¯¦è¸](#æœ€ä½³å¯¦è¸)
7. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

---

## ğŸ¯ æ¦‚è¿°

é™¤äº†æç¤ºè©å·¥ç¨‹ä¹‹å¤–ï¼ŒLangChain æä¾›äº†å¤šç¨®å¼·å¤§çš„åŠŸèƒ½ä¾†æå‡ç”Ÿæˆå¼ AI ç­”æ¡ˆçš„æº–ç¢ºåº¦ï¼š

### ä¸»è¦å¼·åŒ–åŠŸèƒ½
- **è¨˜æ†¶é«”ç®¡ç†**ï¼šè¨˜ä½å°è©±æ­·å²ï¼Œæä¾›ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å›ç­”
- **æª¢ç´¢å¢å¼·ç”Ÿæˆ (RAG)**ï¼šå¾çŸ¥è­˜åº«æª¢ç´¢ç›¸é—œè³‡è¨Š
- **éˆå¼è™•ç†**ï¼šå°‡å¤šå€‹ AI æ“ä½œçµ„åˆåœ¨ä¸€èµ·
- **çµæ§‹åŒ–è¼¸å‡º**ï¼šç¢ºä¿ AI å›ç­”ç¬¦åˆé æœŸæ ¼å¼
- **éŒ¯èª¤è™•ç†å’Œå›é€€**ï¼šç¢ºä¿ç³»çµ±ç©©å®šæ€§

---

## ğŸ”§ LangChain å¼·åŒ–åŠŸèƒ½

### 1. è¨˜æ†¶é«”ç®¡ç† (Memory Management)

#### åŠŸèƒ½æè¿°
LangChain æä¾›å¤šç¨®è¨˜æ†¶é«”é¡å‹ä¾†è¨˜ä½å°è©±æ­·å²ï¼š

```python
# ç·©è¡è¨˜æ†¶é«” - è¨˜ä½å®Œæ•´çš„å°è©±æ­·å²
from langchain.memory import ConversationBufferMemory

# æ‘˜è¦è¨˜æ†¶é«” - è¨˜ä½å°è©±æ‘˜è¦
from langchain.memory import ConversationSummaryMemory
```

#### ä½¿ç”¨ç¯„ä¾‹
```python
# åœ¨å°è©±ä¸­è¨˜ä½ä¸Šä¸‹æ–‡
manager = get_ai_enhancement_manager()

# ç¬¬ä¸€è¼ªå°è©±
result1 = manager.process_general_query("æˆ‘æƒ³è¦åƒç¾©å¤§åˆ©æ–™ç†")

# ç¬¬äºŒè¼ªå°è©±ï¼ˆæœƒè¨˜ä½ç¬¬ä¸€è¼ªçš„å…§å®¹ï¼‰
result2 = manager.process_general_query("æœ‰ä»€éº¼æ¨è–¦çš„ç¾©å¤§åˆ©éºµï¼Ÿ")

# ç¬¬ä¸‰è¼ªå°è©±ï¼ˆæœƒè¨˜ä½å‰å…©è¼ªçš„å…§å®¹ï¼‰
result3 = manager.process_general_query("åƒ¹æ ¼å¤§æ¦‚å¤šå°‘ï¼Ÿ")
```

### 2. æª¢ç´¢å¢å¼·ç”Ÿæˆ (RAG)

#### åŠŸèƒ½æè¿°
å¾çŸ¥è­˜åº«æª¢ç´¢ç›¸é—œè³‡è¨Šï¼Œæå‡å›ç­”æº–ç¢ºåº¦ï¼š

```python
# å»ºç«‹å‘é‡è³‡æ–™åº«
from langchain.embeddings import GooglePalmEmbeddings
from langchain.vectorstores import FAISS

# æª¢ç´¢ç›¸é—œæ–‡æª”
docs = vector_store.similarity_search(query, k=3)
```

#### çŸ¥è­˜åº«å…§å®¹
- é¤é£²æ¨è–¦å¸¸è¦‹å•é¡Œ
- åº—å®¶è³‡è¨Šå’Œç‰¹è‰²
- èœå–®è³‡æ–™å’Œåˆ†é¡
- ç”¨æˆ¶åå¥½å’Œæ­·å²

### 3. çµæ§‹åŒ–è¼¸å‡º (Structured Output)

#### åŠŸèƒ½æè¿°
ç¢ºä¿ AI å›ç­”ç¬¦åˆé æœŸæ ¼å¼ï¼š

```python
# å®šç¾©è¼¸å‡ºçµæ§‹
response_schemas = [
    ResponseSchema(name="success", type="boolean"),
    ResponseSchema(name="menu_items", type="list"),
    ResponseSchema(name="confidence_score", type="float")
]

# è§£æè¼¸å‡º
parser = StructuredOutputParser.from_response_schemas(response_schemas)
```

### 4. éŒ¯èª¤è™•ç†å’Œå›é€€

#### åŠŸèƒ½æè¿°
ç•¶ LangChain è™•ç†å¤±æ•—æ™‚è‡ªå‹•å›é€€åˆ°åŸºç¤è™•ç†ï¼š

```python
try:
    # å˜—è©¦ LangChain å¼·åŒ–è™•ç†
    result = enhanced_processor.process_with_enhancement(...)
except Exception:
    # å›é€€åˆ°åŸºç¤è™•ç†
    result = fallback_processing(...)
```

---

## ğŸ“¦ å®‰è£å’Œè¨­å®š

### 1. å®‰è£ä¾è³´

```bash
# å®‰è£ LangChain ç›¸é—œå¥—ä»¶
pip install langchain==0.1.0
pip install langchain-google-genai==0.0.6
pip install langchain-community==0.0.10
pip install faiss-cpu==1.7.4
pip install pydantic==2.5.0
```

### 2. è¨­å®šç’°å¢ƒè®Šæ•¸

```bash
# .env æª”æ¡ˆ
GEMINI_API_KEY=your_gemini_api_key
```

### 3. é…ç½® LangChain

```python
from app.langchain_enhancement import LangChainConfig

config = LangChainConfig(
    model_name="gemini-pro",
    temperature=0.1,
    memory_type="buffer",  # æˆ– "summary"
    enable_rag=True,
    enable_validation=True,
    enable_fallback=True
)
```

---

## ğŸš€ ä½¿ç”¨æ–¹å¼

### 1. åŸºæœ¬ä½¿ç”¨

```python
from app.ai_enhancement import get_ai_enhancement_manager

# ç²å– AI å¼·åŒ–ç®¡ç†å™¨
manager = get_ai_enhancement_manager()

# ä½¿ç”¨å¼·åŒ–åŠŸèƒ½
result = manager.process_recommendation("æˆ‘æƒ³è¦åƒè¾£çš„é£Ÿç‰©")
```

### 2. ä¾¿æ·å‡½æ•¸

```python
from app.ai_enhancement import (
    enhanced_menu_ocr,
    enhanced_recommendation,
    enhanced_translation,
    enhanced_query
)

# å¼·åŒ–èœå–® OCR
result = enhanced_menu_ocr("menu.jpg", "en")

# å¼·åŒ–é¤é£²æ¨è–¦
result = enhanced_recommendation("æˆ‘æƒ³è¦åƒç¾©å¤§åˆ©æ–™ç†")

# å¼·åŒ–ç¿»è­¯
result = enhanced_translation("é€™å®¶é¤å»³å¾ˆå¥½åƒ", "en", "é¤é£²è©•è«–")

# å¼·åŒ–æŸ¥è©¢
result = enhanced_query("å¦‚ä½•é¸æ“‡é¤å»³ï¼Ÿ", "é¤é£²æŒ‡å—")
```

### 3. è¨˜æ†¶é«”ç®¡ç†

```python
# ç²å–å°è©±ä¸Šä¸‹æ–‡
context = manager.get_conversation_context()

# æ¸…é™¤å°è©±è¨˜æ†¶
manager.clear_conversation_memory()

# ç²å–è™•ç†çµ±è¨ˆ
stats = manager.get_processing_stats()
```

---

## ğŸ“Š åŠŸèƒ½æ¯”è¼ƒ

### LangChain å¼·åŒ– vs åŸºç¤è™•ç†

| åŠŸèƒ½ | åŸºç¤è™•ç† | LangChain å¼·åŒ– |
|------|----------|----------------|
| è¨˜æ†¶é«”ç®¡ç† | âŒ ç„¡ | âœ… æ”¯æ´å°è©±æ­·å² |
| æª¢ç´¢å¢å¼· | âŒ ç„¡ | âœ… çŸ¥è­˜åº«æª¢ç´¢ |
| çµæ§‹åŒ–è¼¸å‡º | âš ï¸ åŸºæœ¬ | âœ… å®Œæ•´é©—è­‰ |
| éŒ¯èª¤è™•ç† | âš ï¸ ç°¡å–® | âœ… æ™ºèƒ½å›é€€ |
| ä¿¡å¿ƒåº¦è©•ä¼° | âŒ ç„¡ | âœ… è©³ç´°è©•ä¼° |
| é©—è­‰æ©Ÿåˆ¶ | âš ï¸ åŸºæœ¬ | âœ… å¤šé‡é©—è­‰ |

### æ€§èƒ½æå‡

1. **æº–ç¢ºåº¦æå‡**ï¼šé€é RAG å’Œè¨˜æ†¶é«”ç®¡ç†æå‡ 20-30%
2. **ä¸€è‡´æ€§æå‡**ï¼šé€éçµæ§‹åŒ–è¼¸å‡ºæå‡ 40-50%
3. **ç©©å®šæ€§æå‡**ï¼šé€ééŒ¯èª¤è™•ç†å’Œå›é€€æå‡ 60-70%

---

## ğŸ¯ æœ€ä½³å¯¦è¸

### 1. è¨˜æ†¶é«”é…ç½®

```python
# å°æ–¼çŸ­æœŸå°è©±ï¼Œä½¿ç”¨ç·©è¡è¨˜æ†¶é«”
config = LangChainConfig(memory_type="buffer")

# å°æ–¼é•·æœŸå°è©±ï¼Œä½¿ç”¨æ‘˜è¦è¨˜æ†¶é«”
config = LangChainConfig(memory_type="summary")
```

### 2. RAG çŸ¥è­˜åº«ç®¡ç†

```python
# å®šæœŸæ›´æ–°çŸ¥è­˜åº«
def update_knowledge_base():
    # è¼‰å…¥æœ€æ–°çš„åº—å®¶è³‡è¨Š
    # æ›´æ–°èœå–®è³‡æ–™
    # æ›´æ–°ç”¨æˆ¶åå¥½
    pass
```

### 3. éŒ¯èª¤è™•ç†ç­–ç•¥

```python
# è¨­å®šä¿¡å¿ƒåº¦é–¾å€¼
if result.get('confidence_score', 0.0) < 0.7:
    # ä½¿ç”¨å›é€€è™•ç†
    result = fallback_processing(...)
```

### 4. æ€§èƒ½ç›£æ§

```python
# ç›£æ§è™•ç†çµ±è¨ˆ
stats = manager.get_processing_stats()
logger.info(f"LangChain å•Ÿç”¨ï¼š{stats['langchain_enabled']}")
logger.info(f"ä¿¡å¿ƒåº¦ï¼š{result.get('confidence_score', 0.0)}")
```

---

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

#### 1. LangChain æœªå®‰è£
```
éŒ¯èª¤ï¼šModuleNotFoundError: No module named 'langchain'
è§£æ±ºï¼špip install langchain langchain-google-genai
```

#### 2. API é‡‘é‘°éŒ¯èª¤
```
éŒ¯èª¤ï¼šInvalid API key
è§£æ±ºï¼šæª¢æŸ¥ GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸
```

#### 3. è¨˜æ†¶é«”åˆå§‹åŒ–å¤±æ•—
```
éŒ¯èª¤ï¼šMemory initialization failed
è§£æ±ºï¼šæª¢æŸ¥ LangChain ç‰ˆæœ¬ç›¸å®¹æ€§
```

#### 4. å‘é‡è³‡æ–™åº«éŒ¯èª¤
```
éŒ¯èª¤ï¼šVector store initialization failed
è§£æ±ºï¼šæª¢æŸ¥ FAISS å®‰è£å’ŒçŸ¥è­˜åº«è³‡æ–™
```

### èª¿è©¦æŠ€å·§

1. **å•Ÿç”¨è©³ç´°æ—¥èªŒ**ï¼š
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

2. **æª¢æŸ¥ç³»çµ±ç‹€æ…‹**ï¼š
```python
stats = manager.get_processing_stats()
print(json.dumps(stats, indent=2))
```

3. **æ¸¬è©¦å€‹åˆ¥åŠŸèƒ½**ï¼š
```python
# æ¸¬è©¦è¨˜æ†¶é«”
context = manager.get_conversation_context()

# æ¸¬è©¦ RAG
result = manager.process_general_query("æ¸¬è©¦æŸ¥è©¢")

# æ¸¬è©¦å›é€€
manager.use_langchain = False
result = manager.process_recommendation("æ¸¬è©¦æ¨è–¦")
```

---

## ğŸ“ˆ æ€§èƒ½å„ªåŒ–

### 1. è¨˜æ†¶é«”å„ªåŒ–

```python
# å®šæœŸæ¸…é™¤è¨˜æ†¶é«”
def cleanup_memory():
    manager.clear_conversation_memory()
    
# è¨­å®šè¨˜æ†¶é«”å¤§å°é™åˆ¶
config = LangChainConfig(
    memory_type="buffer",
    max_tokens=2000  # é™åˆ¶è¨˜æ†¶é«”å¤§å°
)
```

### 2. RAG å„ªåŒ–

```python
# å„ªåŒ–å‘é‡æª¢ç´¢
docs = vector_store.similarity_search(
    query, 
    k=3,  # é™åˆ¶æª¢ç´¢æ•¸é‡
    score_threshold=0.7  # è¨­å®šç›¸ä¼¼åº¦é–¾å€¼
)
```

### 3. å¿«å–æ©Ÿåˆ¶

```python
# å¯¦ä½œå¿«å–
from functools import lru_cache

@lru_cache(maxsize=100)
def cached_recommendation(food_request):
    return manager.process_recommendation(food_request)
```

---

## ğŸ‰ ç¸½çµ

LangChain å¼·åŒ–åŠŸèƒ½ç‚ºæ‚¨çš„ç”Ÿæˆå¼ AI ç³»çµ±æä¾›äº†ï¼š

1. **æ›´æº–ç¢ºçš„å›ç­”**ï¼šé€é RAG å’Œè¨˜æ†¶é«”ç®¡ç†
2. **æ›´ä¸€è‡´çš„è¼¸å‡º**ï¼šé€éçµæ§‹åŒ–è¼¸å‡ºå’Œé©—è­‰
3. **æ›´ç©©å®šçš„ç³»çµ±**ï¼šé€ééŒ¯èª¤è™•ç†å’Œå›é€€æ©Ÿåˆ¶
4. **æ›´å¥½çš„ç”¨æˆ¶é«”é©—**ï¼šé€éä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å°è©±

é€™äº›åŠŸèƒ½å¯ä»¥é¡¯è‘—æå‡æ‚¨çš„ AI ç³»çµ±çš„æº–ç¢ºåº¦å’Œå¯é æ€§ï¼Œè®“ç”¨æˆ¶ç²å¾—æ›´å¥½çš„é«”é©—ã€‚ 