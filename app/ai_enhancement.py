# =============================================================================
# æª”æ¡ˆåç¨±ï¼šapp/ai_enhancement.py
# åŠŸèƒ½æè¿°ï¼šAI å¼·åŒ–æ•´åˆæ¨¡çµ„ï¼Œæ•´åˆ LangChain åŠŸèƒ½åˆ°ç¾æœ‰ AI ç³»çµ±
# ä¸»è¦åŠŸèƒ½ï¼š
# - æ•´åˆç¾æœ‰çš„ AI åŠŸèƒ½èˆ‡ LangChain
# - æä¾›çµ±ä¸€çš„ AI è™•ç†ä»‹é¢
# - æ”¯æ´å¤šç¨® AI ä»»å‹™é¡å‹
# - æä¾›å›é€€æ©Ÿåˆ¶
# =============================================================================

import os
import json
import logging
from typing import Dict, List, Optional, Any
from datetime import datetime

# å°å…¥ç¾æœ‰æ¨¡çµ„
from app.prompts import prompt_engineer
from app.api.helpers import get_gemini_model, process_menu_with_gemini, translate_text
from app.webhook.routes import get_ai_recommendations

# å°å…¥ LangChain å¼·åŒ–æ¨¡çµ„
try:
    from app.langchain_enhancement import get_enhanced_processor, LangChainConfig
    LANGCHAIN_ENHANCEMENT_AVAILABLE = True
except ImportError:
    LANGCHAIN_ENHANCEMENT_AVAILABLE = False
    print("âš ï¸ LangChain å¼·åŒ–æ¨¡çµ„æœªè¼‰å…¥")

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AIEnhancementManager:
    """AI å¼·åŒ–ç®¡ç†å™¨"""
    
    def __init__(self):
        self.enhanced_processor = None
        self.use_langchain = True
        
        # åˆå§‹åŒ– LangChain å¼·åŒ–è™•ç†å™¨
        if LANGCHAIN_ENHANCEMENT_AVAILABLE:
            try:
                config = LangChainConfig(
                    model_name="gemini-2.5-flash",
                    temperature=0.1,
                    memory_type="buffer",
                    enable_rag=True,
                    enable_validation=True,
                    enable_fallback=True
                )
                self.enhanced_processor = get_enhanced_processor()
                logger.info("âœ… LangChain å¼·åŒ–è™•ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.error(f"âŒ LangChain å¼·åŒ–è™•ç†å™¨åˆå§‹åŒ–å¤±æ•—ï¼š{e}")
                self.use_langchain = False
        else:
            self.use_langchain = False
            logger.warning("âš ï¸ LangChain å¼·åŒ–åŠŸèƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¤æ¨¡å¼")
    
    def process_menu_ocr(self, image_path: str, target_language: str = 'en') -> Dict:
        """è™•ç†èœå–® OCRï¼ˆå¼·åŒ–ç‰ˆï¼‰"""
        try:
            if self.use_langchain and self.enhanced_processor:
                # ä½¿ç”¨ LangChain å¼·åŒ–è™•ç†
                logger.info("ğŸ”§ ä½¿ç”¨ LangChain å¼·åŒ–è™•ç†èœå–® OCR")
                
                # è®€å–åœ–ç‰‡
                with open(image_path, 'rb') as img_file:
                    image_data = img_file.read()
                
                result = self.enhanced_processor.process_with_enhancement(
                    prompt_type="menu_ocr",
                    image_data=image_data,
                    target_language=target_language
                )
                
                # é©—è­‰çµæœ
                if result.get("success", False):
                    logger.info(f"âœ… LangChain èœå–® OCR è™•ç†æˆåŠŸï¼Œä¿¡å¿ƒåº¦ï¼š{result.get('confidence_score', 0.0)}")
                    return result
                else:
                    logger.warning("âš ï¸ LangChain è™•ç†å¤±æ•—ï¼Œä½¿ç”¨åŸºç¤æ¨¡å¼")
            
            # å›é€€åˆ°åŸºç¤è™•ç†
            logger.info("ğŸ”„ ä½¿ç”¨åŸºç¤èœå–® OCR è™•ç†")
            return process_menu_with_gemini(image_path, target_language)
            
        except Exception as e:
            logger.error(f"âŒ èœå–® OCR è™•ç†å¤±æ•—ï¼š{e}")
            return {
                "success": False,
                "menu_items": [],
                "store_info": {},
                "processing_notes": f"è™•ç†å¤±æ•—ï¼š{str(e)}",
                "confidence_score": 0.0
            }
    
    def process_recommendation(self, food_request: str, user_language: str = 'zh', 
                             user_history: List = None) -> Dict:
        """è™•ç†é¤é£²æ¨è–¦ï¼ˆå¼·åŒ–ç‰ˆï¼‰"""
        try:
            if self.use_langchain and self.enhanced_processor:
                # ä½¿ç”¨ LangChain å¼·åŒ–è™•ç†
                logger.info("ğŸ”§ ä½¿ç”¨ LangChain å¼·åŒ–è™•ç†é¤é£²æ¨è–¦")
                
                # ç²å–åº—å®¶è³‡æ–™
                from app.models import Store
                stores = Store.query.all()
                store_data = []
                
                for store in stores:
                    store_info = {
                        'store_id': store.store_id,
                        'store_name': store.store_name,
                        'partner_level': store.partner_level,
                        'review_summary': store.review_summary or '',
                        'top_dishes': [
                            store.top_dish_1, store.top_dish_2, store.top_dish_3,
                            store.top_dish_4, store.top_dish_5
                        ],
                        'main_photo_url': store.main_photo_url
                    }
                    store_info['top_dishes'] = [dish for dish in store_info['top_dishes'] if dish]
                    store_data.append(store_info)
                
                result = self.enhanced_processor.process_with_enhancement(
                    prompt_type="recommendation",
                    user_request=food_request,
                    available_stores=json.dumps(store_data, ensure_ascii=False, indent=2),
                    user_history=user_history or []
                )
                
                # é©—è­‰çµæœ
                if result.get("recommendations"):
                    logger.info(f"âœ… LangChain æ¨è–¦è™•ç†æˆåŠŸï¼Œä¿¡å¿ƒåº¦ï¼š{result.get('confidence_score', 0.0)}")
                    return result
                else:
                    logger.warning("âš ï¸ LangChain è™•ç†å¤±æ•—ï¼Œä½¿ç”¨åŸºç¤æ¨¡å¼")
            
            # å›é€€åˆ°åŸºç¤è™•ç†
            logger.info("ğŸ”„ ä½¿ç”¨åŸºç¤é¤é£²æ¨è–¦è™•ç†")
            return get_ai_recommendations(food_request, user_language)
            
        except Exception as e:
            logger.error(f"âŒ é¤é£²æ¨è–¦è™•ç†å¤±æ•—ï¼š{e}")
            return {
                "recommendations": [],
                "analysis": {"error": f"è™•ç†å¤±æ•—ï¼š{str(e)}"},
                "confidence_score": 0.0
            }
    
    def process_translation(self, text: str, target_language: str = 'en', 
                          context: str = None) -> Dict:
        """è™•ç†ç¿»è­¯ï¼ˆå¼·åŒ–ç‰ˆï¼‰"""
        try:
            if self.use_langchain and self.enhanced_processor:
                # ä½¿ç”¨ LangChain å¼·åŒ–è™•ç†
                logger.info("ğŸ”§ ä½¿ç”¨ LangChain å¼·åŒ–è™•ç†ç¿»è­¯")
                
                result = self.enhanced_processor.process_with_enhancement(
                    prompt_type="translation",
                    original_text=text,
                    target_language=target_language,
                    context=context or ""
                )
                
                # é©—è­‰çµæœ
                if result.get("translated_text"):
                    logger.info(f"âœ… LangChain ç¿»è­¯è™•ç†æˆåŠŸï¼Œä¿¡å¿ƒåº¦ï¼š{result.get('confidence_score', 0.0)}")
                    return result
                else:
                    logger.warning("âš ï¸ LangChain è™•ç†å¤±æ•—ï¼Œä½¿ç”¨åŸºç¤æ¨¡å¼")
            
            # å›é€€åˆ°åŸºç¤è™•ç†
            logger.info("ğŸ”„ ä½¿ç”¨åŸºç¤ç¿»è­¯è™•ç†")
            translated_text = translate_text(text, target_language)
            return {
                "translated_text": translated_text,
                "confidence_score": 0.8,
                "translation_notes": "åŸºç¤ç¿»è­¯è™•ç†"
            }
            
        except Exception as e:
            logger.error(f"âŒ ç¿»è­¯è™•ç†å¤±æ•—ï¼š{e}")
            return {
                "translated_text": text,
                "confidence_score": 0.0,
                "translation_notes": f"ç¿»è­¯å¤±æ•—ï¼š{str(e)}"
            }
    
    def process_general_query(self, user_query: str, context: str = None) -> Dict:
        """è™•ç†ä¸€èˆ¬æŸ¥è©¢ï¼ˆå¼·åŒ–ç‰ˆï¼‰"""
        try:
            if self.use_langchain and self.enhanced_processor:
                # ä½¿ç”¨ LangChain å¼·åŒ–è™•ç†
                logger.info("ğŸ”§ ä½¿ç”¨ LangChain å¼·åŒ–è™•ç†ä¸€èˆ¬æŸ¥è©¢")
                
                result = self.enhanced_processor.process_with_enhancement(
                    prompt_type="general",
                    user_query=user_query,
                    context=context or ""
                )
                
                # é©—è­‰çµæœ
                if result.get("answer"):
                    logger.info(f"âœ… LangChain æŸ¥è©¢è™•ç†æˆåŠŸï¼Œä¿¡å¿ƒåº¦ï¼š{result.get('confidence_score', 0.0)}")
                    return result
                else:
                    logger.warning("âš ï¸ LangChain è™•ç†å¤±æ•—ï¼Œä½¿ç”¨åŸºç¤æ¨¡å¼")
            
            # å›é€€åˆ°åŸºç¤è™•ç†
            logger.info("ğŸ”„ ä½¿ç”¨åŸºç¤æŸ¥è©¢è™•ç†")
            model = get_gemini_model()
            prompt = f"""
ç”¨æˆ¶æŸ¥è©¢ï¼š{user_query}

ä¸Šä¸‹æ–‡ï¼š{context or ""}

è«‹æä¾›æº–ç¢ºã€æœ‰ç”¨çš„å›ç­”ã€‚
"""
            response = model.generate_content(prompt)
            return {
                "answer": response.text,
                "confidence_score": 0.7,
                "suggestions": []
            }
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥è©¢è™•ç†å¤±æ•—ï¼š{e}")
            return {
                "answer": "æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•è™•ç†æ‚¨çš„æŸ¥è©¢ã€‚è«‹ç¨å¾Œå†è©¦ã€‚",
                "confidence_score": 0.0,
                "suggestions": []
            }
    
    def get_conversation_context(self) -> str:
        """ç²å–å°è©±ä¸Šä¸‹æ–‡"""
        if self.enhanced_processor:
            return self.enhanced_processor.get_conversation_summary()
        return ""
    
    def clear_conversation_memory(self):
        """æ¸…é™¤å°è©±è¨˜æ†¶"""
        if self.enhanced_processor:
            self.enhanced_processor.clear_memory()
            logger.info("ğŸ—‘ï¸ å°è©±è¨˜æ†¶å·²æ¸…é™¤")
    
    def get_processing_stats(self) -> Dict:
        """ç²å–è™•ç†çµ±è¨ˆè³‡è¨Š"""
        stats = {
            "langchain_enabled": self.use_langchain,
            "enhanced_processor_available": self.enhanced_processor is not None,
            "timestamp": datetime.now().isoformat()
        }
        
        if self.enhanced_processor:
            stats["memory_type"] = self.enhanced_processor.config.memory_type
            stats["rag_enabled"] = self.enhanced_processor.config.enable_rag
            stats["validation_enabled"] = self.enhanced_processor.config.enable_validation
        
        return stats

# å…¨åŸŸ AI å¼·åŒ–ç®¡ç†å™¨å¯¦ä¾‹
ai_enhancement_manager = AIEnhancementManager()

def get_ai_enhancement_manager() -> AIEnhancementManager:
    """ç²å– AI å¼·åŒ–ç®¡ç†å™¨å¯¦ä¾‹"""
    return ai_enhancement_manager

# ä¾¿æ·å‡½æ•¸
def enhanced_menu_ocr(image_path: str, target_language: str = 'en') -> Dict:
    """å¼·åŒ–èœå–® OCR è™•ç†"""
    return ai_enhancement_manager.process_menu_ocr(image_path, target_language)

def enhanced_recommendation(food_request: str, user_language: str = 'zh', 
                          user_history: List = None) -> Dict:
    """å¼·åŒ–é¤é£²æ¨è–¦è™•ç†"""
    return ai_enhancement_manager.process_recommendation(food_request, user_language, user_history)

def enhanced_translation(text: str, target_language: str = 'en', context: str = None) -> Dict:
    """å¼·åŒ–ç¿»è­¯è™•ç†"""
    return ai_enhancement_manager.process_translation(text, target_language, context)

def enhanced_query(user_query: str, context: str = None) -> Dict:
    """å¼·åŒ–æŸ¥è©¢è™•ç†"""
    return ai_enhancement_manager.process_general_query(user_query, context) 