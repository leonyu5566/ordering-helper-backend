#!/usr/bin/env python3
"""
LangChain åŠ é€Ÿè™•ç†æ¨¡çµ„
ä½¿ç”¨ Gemini 2.5 Flash é€²è¡Œé«˜æ•ˆè™•ç†
"""

import os
import json
import logging
from typing import Dict, List, Optional
from google import genai

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class LangChainAcceleration:
    """LangChain åŠ é€Ÿè™•ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åŠ é€Ÿè™•ç†å™¨"""
        try:
            # åˆå§‹åŒ– Gemini 2.5 Flash
            genai.Client(api_key=os.getenv('GEMINI_API_KEY'))
            self.client = genai.Client()
            logger.info("âœ… LangChain åŠ é€Ÿè™•ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ LangChain åŠ é€Ÿè™•ç†å™¨åˆå§‹åŒ–å¤±æ•—ï¼š{e}")
            self.client = None
    
    def process_text(self, text: str, task_type: str = "general") -> Dict:
        """è™•ç†æ–‡å­—ä»»å‹™"""
        if not self.client:
            return {"error": "è™•ç†å™¨æœªåˆå§‹åŒ–"}
        
        try:
            # æ ¹æ“šä»»å‹™é¡å‹é¸æ“‡ä¸åŒçš„æç¤ºè©
            if task_type == "translation":
                prompt = f"è«‹å°‡ä»¥ä¸‹æ–‡å­—ç¿»è­¯ç‚ºè‹±æ–‡ï¼š{text}"
            elif task_type == "summary":
                prompt = f"è«‹ç¸½çµä»¥ä¸‹æ–‡å­—ï¼š{text}"
            else:
                prompt = f"è«‹è™•ç†ä»¥ä¸‹æ–‡å­—ï¼š{text}"
            
            response = self.client.models.generate_content(
                model="gemini-2.5-flash",
                contents=[prompt],
                config={
                    "thinking_config": genai.types.ThinkingConfig(thinking_budget=128)
                }
            )
            
            return {
                "success": True,
                "result": response.text.strip(),
                "task_type": task_type
            }
            
        except Exception as e:
            logger.error(f"æ–‡å­—è™•ç†å¤±æ•—ï¼š{e}")
            return {
                "success": False,
                "error": str(e),
                "task_type": task_type
            }
    
    def process_image(self, image_path: str, task_type: str = "ocr") -> Dict:
        """è™•ç†åœ–ç‰‡ä»»å‹™"""
        if not self.client:
            return {"error": "è™•ç†å™¨æœªåˆå§‹åŒ–"}
        
        try:
            from PIL import Image
            import io
            
            # è®€å–åœ–ç‰‡
            with open(image_path, 'rb') as img_file:
                image_bytes = img_file.read()
            
            image = Image.open(io.BytesIO(image_bytes))
            
            # æ ¹æ“šä»»å‹™é¡å‹é¸æ“‡ä¸åŒçš„æç¤ºè©
            if task_type == "ocr":
                prompt = "è«‹è¾¨è­˜é€™å¼µåœ–ç‰‡ä¸­çš„æ–‡å­—å…§å®¹ï¼š"
            elif task_type == "description":
                prompt = "è«‹æè¿°é€™å¼µåœ–ç‰‡çš„å…§å®¹ï¼š"
            else:
                prompt = "è«‹åˆ†æé€™å¼µåœ–ç‰‡ï¼š"
            
            response = self.client.models.generate_content(
                model="gemini-2.5-flash",
                contents=[
                    prompt,
                    image
                ],
                config={
                    "thinking_config": genai.types.ThinkingConfig(thinking_budget=256)
                }
            )
            
            return {
                "success": True,
                "result": response.text.strip(),
                "task_type": task_type
            }
            
        except Exception as e:
            logger.error(f"åœ–ç‰‡è™•ç†å¤±æ•—ï¼š{e}")
            return {
                "success": False,
                "error": str(e),
                "task_type": task_type
            }
    
    def batch_process(self, items: List[Dict]) -> List[Dict]:
        """æ‰¹æ¬¡è™•ç†å¤šå€‹é …ç›®"""
        results = []
        
        for item in items:
            if item.get("type") == "text":
                result = self.process_text(
                    item.get("content", ""),
                    item.get("task_type", "general")
                )
            elif item.get("type") == "image":
                result = self.process_image(
                    item.get("content", ""),
                    item.get("task_type", "ocr")
                )
            else:
                result = {"success": False, "error": "ä¸æ”¯æ´çš„é …ç›®é¡å‹"}
            
            results.append(result)
        
        return results

def get_acceleration_processor() -> LangChainAcceleration:
    """å–å¾—åŠ é€Ÿè™•ç†å™¨å¯¦ä¾‹"""
    return LangChainAcceleration()

def test_acceleration():
    """æ¸¬è©¦åŠ é€ŸåŠŸèƒ½"""
    print("ğŸ§ª æ¸¬è©¦ LangChain åŠ é€ŸåŠŸèƒ½...")
    
    processor = get_acceleration_processor()
    
    # æ¸¬è©¦æ–‡å­—è™•ç†
    text_result = processor.process_text("ä½ å¥½ï¼Œä¸–ç•Œ", "translation")
    print(f"æ–‡å­—è™•ç†çµæœï¼š{text_result}")
    
    print("âœ… LangChain åŠ é€ŸåŠŸèƒ½æ¸¬è©¦å®Œæˆ")

if __name__ == "__main__":
    test_acceleration() 